\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}        % so we can use the 'pretty' empty set
\usepackage{tipa}
\usepackage{graphicx}           % purdy pitchers
\usepackage{algorithmic}
\usepackage{phonrule}

\usepackage{cite}
\usepackage{apacite}

\newtheorem{definition}{Definition}

\title{An algorithm to assign features to a set of phonological classes}
\author{}
\author{
  Mayer, Connor \\
  \texttt{connormayer@ucla.edu}
  \and
  Daland, Robert \\
  \texttt{r.daland@gmail.com}
}
\date{\vspace{-5ex}}							% Activate to display a given date or no date

\begin{document}
\maketitle

\begin{abstract}
This squib describes a dynamic programming algorithm which assigns features to a set of phonological classes. The input consists of a set of classes, each containing one or more segments; in other words, a subset of the powerset of a segmental alphabet $\Sigma$. If a class can be generated as the union of existing features ( = intersection of already-processed classes), those features are propagated to every segment in the class. Otherwise, a new feature/value pair is assigned. The algorithm comes in 4 flavors, which differ with respect to complementation and how negative values are assigned. We show that these variants yield \textit{privative specification}, \textit{contrastive underspecification}, \textit{contrastive specification}, and \textit{full specification}, respectively. The main text sets out necessary background, and illustrates each variant of the algorithm. The Appendix formally proves that each algorithm is sound.
\end{abstract}

\section{Introduction}
Distinctive features are the building blocks of phonological theory. Features represent phonetic qualities of speech sounds, and can be used in isolation or combination to describe individual sounds or classes of sounds \cite<e.g.,>{Saussure1959, JakobsonEtAl1952}. This captures the generalization that sounds with similar phonetic properties tend to pattern similarly in the phonologies of languages. For example, the feature \phonfeat{-voice} picks out all sounds without voicing, while the combination of features \phonfeat{-voice \\ -continuant} picks out, for example, the English voiceless stop series.

Distinctive features have traditionally been described as \textit{innate}: that is, all the sounds in the world's languages can be described by the same finite set of features, and the task of the language learner is to decompose the sounds of the ambient language into their consituent features to build a phonological grammar \cite<e.g.,>{ChomskyHalle1968}. This implies that the phonological classes we see in natural languages should be definable by combinations of these innate features.

Although feature theory has been extremely productive in phonology, there is evidence that shows many phonological classes cannot be described as a combination of phonetically-based features. For example, \citeA{Mielke2008} conducted a survey of almost 600 languages and showed that, at best, any modern feature system can categorize 71\% of attested sound classes. The remaining 29\% are \textit{phonetically disparate classes}, which require less theoretically-appealing descriptions combinations of features to be described, such as \textsc{XOR} feature classes (e.g., \phonfeat{-voice} or \phonfeat{-continuant} but not both).

The preponderance of these phonetically disparate classes has led some researchers to propose that distinctive features are \textit{learned} and \textit{language-specific} \cite<e.g.,>{Blevins2004, Mielke2008, MacWhinneyOGrady2015, ArchangeliPulleyblank2015}: learners are able to group sounds in their languages into classes regardless of whether they have any phonetic commonality. The striking regularities that exist across languages are explained as by-products of general human cognitive capabilities, such as categorization, sensitivity to frequency, and the ability to generalize, as well as the properties of the human vocal tract and auditory system.

This sets the stage for the goals of the current paper, which are somewhat modest. The basic question we address is the inverse of how features have typically been approached: rather than asking what classes a feature system defines, we instead focus on how a feature system can be learned from a set of predetermined classes. We begin by defining a formal notation for feature systems. We then describe the \textit{intersectional closure} of a set of classes, which must be generated by any featurization of that set. Using the intersectional closure as a tool for efficient calculation, we then describe a suite of algorithms for learning various types of featurizations for a set of input classes and prove their correctness, examining as we do the trade offs between number of classes and number of features that each featurization method makes.

This paper makes several important contributions: first, it demonstrates a method for working backwards to feature systems underpinning learned classes of sounds and provides the code for use in future research. Second, it provides a detailed formalization of what a featurization of classes entails, allowing careful reasoning about the expressiveness of such featurizations. Finally, by comparing multiple types of featurization of a set of classes, it makes explicit predictions about what classes should be describable under each type, which may be useful for future experimental phonological research.

\section{Definitions and notation}

Let $\Sigma$ denote an alphabet of segments. We will use the term \textit{class} to mean a subset of $\Sigma$. We will also use the notation $\mathcal P(X)$ to indicate the \textit{powerset} of $X$ -- the set of all subsets of $X$, including the empty set $\varnothing$ and $X$ itself.

\subsection{Classes and class systems}

A \textit{class system} $\mathcal C$ over an alphabet $\Sigma$ is any subset of $\mathcal P(\Sigma)$ which includes $\Sigma$ itself. Formally, $\mathcal C = \{ C_i \}_{i=1}^N$, where each $C_i \subset \Sigma$. Fig~\ref{fig:lattice} illustrates this definition with a class system over a set of vowels.

% show an example of a natural class system: a vowel harmony lattice
% TODO: it would be great to modify this figure so the 'stray' singletons on the right are on the same 'tier' as the other singletons
\begin{figure}[h]
\includegraphics[width=0.9\textwidth]{vowelHarmony_unicode.png}
\caption{Vowel harmony lattice}
\label{fig:lattice}
\end{figure}

In this graph, each node corresponds to a class, and a downward arrow from class $C_i$ to class $C_j$ indicates that $C_j \subset C_i$. To be more precise, downward arrows indicate that there is no `intervening' class $C_k$. For example, the front vowels \{\textipa{OE}, \textipa{y}, \textipa{E}, \textipa{i}\} intervene between all vowels and \{\textipa{E}\}, so we do not include an arrow from the top node to the \{\textipa{E}\}, node. This relation will prove important for the algorithms we discuss later, and so we formalize it here: 

\begin{definition}
	$C_i$ is a \textit{parent} of $C_j$ (and $C_j$ is a \textit{daughter} of $C_i$) if and only if $C_j \subset C_i$, and $\nexists C_k \in \mathcal C \, [C_j \subset C_k \subset C_i]$.
\end{definition}

\subsubsection{Representing subset relations as matrices}

\vspace{\baselineskip} Any directed graph like Fig~\ref{fig:lattice} has an equivalent representation with a square matrix. Row $i$ is identified with class $C_i$, column $j$ with $C_j$; and the value in the $(i,j)$ cell indicates the relationship between $C_i$ and $C_j$. For binary relations like the subsethood and daughterhood, it is convenient to use the Boolean field: the set $\{T, \, F\}$ with operations $\cdot$ (logical \textsc{and}), $+$ (logical \textsc{or}), and additive inverse $-$ (logical \textsc{not}). The \textit{subset matrix} is defined thus:

$$S_{ij} = \begin{cases}
                T & \quad \text{if } C_j \subset C_i \\
                F & \quad \text{otherwise}
                \end{cases}$$

\noindent The advantage of writing a relation in this way is that fundamental matrix operations correspond to various measures of interest. For example, when $S$ is defined as above, and $S^2$ is calculated from ordinary matrix multiplication, then $S^2$ indicates the subset-of-a-subset relation, which corresponds graphically to 'paths' of length 2 on a subset graph. In other words, $(S^2)_{ij} = T$ means there is a $C_k$ such that $S_{ik} = T \textsc{ and } S_{kj} = T$. If we further let \textsc{and} denote the element-wise multiplication operator, then the \textit{daughter matrix} can be computed from the subset matrix as follows: 

$$D = S \textsc{ and } -S^2$$

\noindent This matrix expressed the daughterhood relation: $D_{ij} = T$ means $C_j$ is a daughter of $C_i$.\footnote{Similarly, the subset matrix can be expressed as the sum of all powers of the daughter matrix, \mbox{$S = \sum_{n=1}^N D^n$}. For this problem, we generally expect to compute $D$ from $S$, rather than \textit{vice versa}.} The matrix $D$ is of central importance to the featurization algorithms described later.

\subsection{Feature systems and featurizations}

% definition of feature system
\vspace{\baselineskip} A \textit{feature system} is a tuple $(\mathcal F, \Sigma, \mathcal V)$ where \begin{itemize}
    \item $\Sigma$ is a segmental alphabet, 
    \item $\mathcal V$ is a set of values, and 
    \item $\mathcal F$ is a \textit{featurization}: a set of features $\{f_j\}_{j=1}^M$, where each feature is a function $f: \Sigma \rightarrow \mathcal V$ mapping segments to feature values
    \end{itemize}

\noindent To illustrate, a feature system for the vowel harmony lattice shown in Fig.~\ref{fig:lattice} is shown below:

% table with featurization of vowel harmony lattice
\begin{table}[h]
    \centering
    \begin{tabular} {|c||c|c|c|c|c|}
    \hline
        $\sigma$ & front & back & low & high & round \\ \hline
        \textipa{i} & + & -- & -- & + & -- \\
        \textipa{y} & + & -- & -- & + & + \\
        \textipa{W} & -- & + & -- & + & -- \\
        \textipa{u} & -- & + & -- & + & + \\
        \textipa{E} & + & -- & -- & -- & -- \\
        \textipa{\oe} & + & -- & -- & -- & + \\
        \textipa{2} & -- & + & -- & -- & -- \\
        \textipa{O} & -- & + & -- & -- & + \\
        \textipa{a} & -- & + & + & -- & -- \\
        \hline
    \end{tabular}
    \caption{Example of a feature system.}
    \label{table:featurization}
\end{table}

\noindent In the next subsection we formalize featural descriptors, which relate classes and feature systems.

\subsection{Featural descriptors}

Let $(\mathcal F, \Sigma, \mathcal V)$ be a feature system. We restrict $\mathcal V$ to the following possibilities: \begin{itemize}
    \item \textit{privative specification}: $\mathcal V = \{ +, 0 \}$
    \item \textit{full specification}: $\mathcal V = \{ +, - \}$
    \item \textit{contrastive specification}: $\mathcal V = \{ +, -, 0 \}$
    \end{itemize}

A \textit{featural descriptor} $\mathbf{e}$ is a set of feature/value pairs where the values cannot be $0$, $\mathbf{e} \subset (\mathcal V \setminus \{0\}) \times \mathcal F$. For example, $\mathbf{e} = [+ \text{front}, - \text{low}]$ is a featural descriptor.

To relate featural descriptors and phonological classes, note that every featural descriptor $\mathbf{e}$ can be expressed in the form $\mathbf{e} = \{\alpha_k F_k\}_{k=1}^K$, where each $\alpha_k$ is a value in $\mathcal V \setminus \{ 0 \}$, and each $F_k$ is some feature function $f_j \in \mathcal F$. Informally, we say that a featural descriptor describes the class of segments which have (at least) the feature/value pairs it contains. Formally, we write $\langle \mathbf{e} \rangle$ to indicate the natural class that corresponds to the featural descriptor $\mathbf{e}$:

$$ \langle \, \{\alpha_k F_k\}_{k=1}^K \, \rangle = \{x \in \Sigma \, | \, F_k(x) = \alpha_k \text{ for every } k \} $$

\vspace{\baselineskip} \noindent We use the notation $\mathcal V^\mathcal F$ to denote the powerset of $(\mathcal V \setminus \{0\}) \times \mathcal F$, i.e. the set of all licit featural descriptors. Lastly, we define $\langle \mathcal V^\mathcal F \rangle = \{ \langle \mathbf{e} \rangle \, | \, \mathbf{e} \in \mathcal V^\mathcal F \}$, the set of all natural classes described by some featural descriptor in $\mathcal V^\mathcal F$. We say that the feature system $(\mathcal F, \Sigma, \mathcal V)$ generates the natural class system $\langle \mathcal V^\mathcal F \rangle$.

Note that while every featural descriptor in $\mathcal V^\mathcal F$ picks out a class in $\langle \mathcal V^\mathcal F \rangle$, the two are not in 1-1 correspondence. This is because the same class can often be described by multiple featural descriptors. For example, under the the feature system of Table~\ref{table:featurization}, the featural descriptor $[+\text{front}]$ picks out the same class as the featural descriptor $[+ \text{front}, - \text{low}]$ (namely, the front vowels). Moreover, the featural descriptors $[+\text{front}, -\text{front}]$ and $[+\text{high}, +\text{low}]$ both pick out the empty set.

\vspace{\baselineskip} We say that a feature system $(\mathcal F, \Sigma, \mathcal V)$ \textit{covers} a natural class system $\mathcal C$ if $\mathcal C \subset \langle \mathcal V^\mathcal F \rangle$; in other words if the feature system provides a distinct featural representation for every class in $\mathcal C$. In the remainder of this squib, we show how to construct a feature system that covers an arbitrary natural class system $\mathcal C$.

We begin with a worked-out example illustrating the difference between privative and full specification with the same segmental alphabet. Then we introduce the notion of intersectional closure, which leads naturally to a featurization algorithm for privative specification. Simple modifications yield algorithms for contrastive and full specification.

\subsection{Example}

Let $\Sigma =$ \{R, D, T\}. Informally, the reader may think of [R] as a sonorant, [D] as a voiced obstruent, and [T] as a voiceless obstruent; accordingly we use the feature names $son$ and $vcd$. In this section, we illustrate the consequences of privative versus full specification, using featurizations that are isomorphic (that is, they match on the $+$ values, and differ only as to whether the non-$+$ values are $0$ or $-$). We begin with Table ~\ref{table:privative}.

% table with featurization of sonorants, voiced obstruents, and voiceless obstruents
\begin{table}[h]
    \centering
    \begin{tabular} {|c||c|c|}
    \hline
        $\sigma$ & son & vcd \\ \hline
        R & + & + \\
        D & 0 & + \\
        T & 0 & 0 \\
        \hline
    \end{tabular}
    \caption{Sonorants and obstruents with privative specification.}
    \label{table:privative}
\end{table}

\noindent The set of natural classes it describes, and the simplest featural descriptor for each, are shown below: \begin{itemize}
  \item $[\,]$ -- \{R, D, T\}
  \item $[+\text{son}]$ -- \{R\}
  \item $[+\text{vcd}]$ -- \{R, D\}
  \end{itemize}
  
\noindent Note that this featurization provides no featural descriptor that uniquely picks out the voiceless obstruent [T], no way to pick out the obstruents [T] and [D] to the exclusion of [R], and no way to pick out the voiced obstruent [D] without [R].

Next, consider the isomorphic featurization in which the $0$'s from Table ~\ref{table:privative} are replaced with $-$'s:

% table with featurization of sonorants, voiced obstruents, and voiceless obstruents
\begin{table}[h]
    \centering
    \begin{tabular} {|c||c|c|}
    \hline
        $\sigma$ & son & vcd \\ \hline
        R & + & + \\
        D & -- & + \\
        T & -- & -- \\
        \hline
    \end{tabular}
    \caption{Sonorants and obstruents with full specification.}
    \label{table:full}
\end{table}

\noindent The set of natural classes this featurization describes is much larger, because the number of (extensionally distinct) featural descriptors is larger: \begin{itemize}
    \item $[\,] =$ \{R, D, T\}
    \item $[+\text{son}] =$ \{R\}
    \item $[-\text{son}] =$ \{D, T\}
    \item $[+\text{vcd}] =$ \{R, D\}
    \item $[-\text{vcd}] =$ \{T\}
    \item $[-\text{son},+\text{vcd}] =$ \{D\}
    \item $[+\text{son},-\text{son}] = \varnothing$
    \end{itemize}

\noindent An important generalization emerges from comparing these featurizations: the more $0$'s in the featurization, the greater the number of distinct feature functions that will be required to cover the same natural class system. In one sense, privative specification is more complex, because it will normally involve more features. However, in another sense, it is simpler, because there are only $+$ values to handle and because it will result in fewer natural classes. Therefore, we will treat privative specification first. Prior to this, we introduce the notion of intersectional closure -- the data structure that proves useful for efficiently assigning a privative feature system.

\section{Intersectional closure}

In this section we define the \textit{intersectional closure} of a natural class system $\mathcal C$. We prove that if a feature system is expressive enough to generate all the classes in $\mathcal C$, it generates the intersectional closure. Then we give a dynamic programming algorithm which efficiently computes the intersectional closure of a natural class system, as well as the intersection relation. It turns out that these structures are exactly what is needed to efficiently assign a feature system.

\vspace{\baselineskip} The \textit{intersectional closure} of $\mathcal C$, denoted $\mathcal C_\cap$, is the natural class system consisting of every class that can be generated by the intersection of finitely many classes in $\mathcal C$. Formally, $\mathcal C_\cap = \{\, \bigcap {C' \in P}  \, | \, \exists P \in \mathcal P(\mathcal C) \}$ (where $\mathcal P(\mathcal C)$ is the powerset of $\mathcal C$). We show that if a feature system $(\mathcal F, \Sigma, \mathcal V)$ is rich enough to cover $\mathcal C$, it generates $\mathcal C_\cap$.

\vspace{\baselineskip} \noindent \textbf{Lemma}: If $\mathbf{e}_i, \mathbf{e}_j \in \mathcal V^\mathcal F$, then $\langle \mathbf{e}_i \cup \mathbf{e}_j \rangle =  \langle \mathbf{e}_i \rangle \cap \langle \mathbf{e}_j \rangle$.

\textit{Proof}: The proof proceeds by showing that $\langle \mathbf{e}_i \cup \mathbf{e}_j \rangle \subset  \langle \mathbf{e}_i \rangle \cap \langle \mathbf{e}_j \rangle$ and $ \langle \mathbf{e}_i \rangle \cap \langle \mathbf{e}_j \rangle \subset \langle \mathbf{e}_i \cup \mathbf{e}_j \rangle$.
Let $C_i = \langle \mathbf{e}_i \rangle$ and $C_j = \langle \mathbf{e}_j \rangle$.
First, suppose $x \in C_i \cap C_j$. Then $x \in C_i$. By definition, $x$ must have the features in $\mathbf{e}_i$.
Similarly, $x \in C_j$, and therefore must have the features in $\mathbf{e}_j$.
Thus, $x$ has the features in $\mathbf{e}_i \cup \mathbf{e}_j$. This shows that $C_i \cap C_j \subset \langle \mathbf{e}_i \cup \mathbf{e}_j \rangle$.
Now, suppose $x \in \langle \mathbf{e}_i \cup \mathbf{e}_j \rangle$. Then $x$ has all the features of $\mathbf{e}_i$, and so $x \in C_i$.
Similarly, $x$ has all the features of $\mathbf{e}_j$, so $x \in C_j$. Therefore $x \in C_i \cap C_j$. This shows that $\langle \mathbf{e}_i \cup \mathbf{e}_j \rangle \subset C_i \cap C_j$.
Since both $C_i \cap C_j$ and $\langle \mathbf{e}_i \cup \mathbf{e}_j \rangle$ are subsets of each other, they are equal.

\vspace{\baselineskip} \noindent \textbf{Theorem}: Let $\mathcal C = \{C_i\}_{i=1}^n$ be a natural class system and $(\mathcal F, \Sigma, \mathcal V)$ a feature set. If $\mathcal C \subset \langle \mathcal V^\mathcal F \rangle$, then $\mathcal C_\cap \subset\langle \mathcal V^\mathcal F \rangle $.

\textit{Proof}: Let $C$ be an arbitrary class in $\mathcal C_\cap$. By definition of $\mathcal C_\cap$, there exist $\{C_i \in \mathcal C\}_{i=1}^n$ such that and $C = \bigcap_i \, C_i$. The hypothesis that $\mathcal C \subset \langle \mathcal V^\mathcal F \rangle $ implies that for every $C_i$ in $\mathcal C$, there exists a featural descriptor $\mathbf{e}_i$ such that $\langle \mathbf{e}_i \rangle = C_i$. Thus, $C = \bigcap_i C_i = C_1 \cap C_2 \cap \ldots \cap C_n$ can also be written $C = \bigcap_i \, \langle \mathbf{e}_i \rangle = \langle \mathbf{e}_1 \rangle \cap  \langle \mathbf{e}_2 \rangle \cap \ldots \cap  \langle \mathbf{e}_n \rangle$. It follows by induction that $C = \langle \bigcup_i  \mathbf{e}_i \rangle$:

$C = \langle \mathbf{e}_1 \rangle \cap  \langle \mathbf{e}_2 \rangle \cap \ldots \cap  \langle \mathbf{e}_n \rangle$

\quad $ = \langle \mathbf{e}_1 \cup \mathbf{e}_2 \rangle \cap \mathbf{e}_3 \cap \ldots \cap \langle \mathbf{e}_n \rangle$

\quad $ = \langle \mathbf{e}_1 \cup \mathbf{e}_2 \cup \mathbf{e}_3 \rangle \cap \ldots \cap \langle \mathbf{e}_n \rangle$

\quad $\ldots$

\quad $= \langle \mathbf{e}_1 \cup \mathbf{e}_2 \cup \ldots \cup \mathbf{e}_n \rangle$

\quad $= \langle \bigcup_i  \mathbf{e}_i \rangle$

\noindent The preceding chain of logic demonstrates that if a class can be expressed as the intersection of natural classes in $\mathcal C$, then its features are the union of the features in each of those classes. Thus, if $(\mathcal F, \Sigma, \mathcal V)$ covers $\mathcal C$, it covers the intersectional closure. This completes the proof.


\vspace{\baselineskip} Next, we give an algorithm which computes the intersectional closure, a modified variant of Dijkstra's shortest-paths algorithm. As we will show later, the computational benefit of precomputing the intersectional closure is that it efficiently computes the intersection relation, which reduces the computational complexity of the featurization algorithm. We assume that the input is a natural class system $\mathcal C = \{C_i\}_{i=1}^N$.

\vspace{\baselineskip} \noindent \begin{algorithmic}
    \ENSURE $\mathcal C_\cap$ is the intersectional closure of $\mathcal C$
    \ENSURE $\mathcal I(i,j) = k$ whenever $C_i \cap C_j = C_k$ (for all $i, j, k$)
    \STATE
    \STATE $\mathcal C_\cap \leftarrow \mathcal C$ \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \COMMENT{ordered list of classes}
    \STATE $N \leftarrow | \mathcal C_\cap |$ \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \COMMENT{size of $\mathcal C_\cap$}
    \STATE $\mathcal Q \leftarrow \{ (i, j) \, | \, 1 \leq i, j \leq N, i \neq j \}$ \quad \COMMENT{queue of natural class index pairs}
    \STATE $\mathcal I \leftarrow \varnothing$ \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \COMMENT{hash table: $(i, j) \rightarrow k$ means $C_k = C_i \cap C_j$}
    \STATE
    \WHILE{$\mathcal Q \neq \varnothing$}
        \STATE $(i, j) \leftarrow \textsc{pop}(\mathcal Q)$
        \IF{ \NOT ($C_j \subset C_i$ \OR $C_i \subset C_j$)}
            \STATE $C \leftarrow C_i \cap C_j$
            \IF{$C \in \mathcal C_\cap$}
                \STATE $\mathcal I(i, j) \leftarrow \textsc{index}(\mathcal C_\cap, \, C)$
            \ELSE
                \STATE $\textsc{append}(\mathcal C_\cap, \, C)$
                \STATE $N \leftarrow N+1$
                \FOR{$k=1$ to $N$}
                    \STATE $\textsc{push} \quad (k, N) \rightarrow \mathcal Q$
                    \STATE $\textsc{push} \quad(N, k) \rightarrow \mathcal Q$
                \ENDFOR
            \ENDIF
        \ENDIF
    \ENDWHILE
\end{algorithmic}

\section{Privative specification}

\vspace{\baselineskip} \noindent \begin{algorithmic}
	\REQUIRE $\mathcal V = \{ +, 0 \}$
	\REQUIRE Precompute $C' <- \textsc{IntersectionalClosure}(C)$
	\REQUIRE $\mathcal C'$ is sorted in decreasing order of size ($\forall i, j \, [i < j \rightarrow |C'_i| \geq |C'_j|$)
	\REQUIRE parent matrix $P$ ($|C'| \times |C'|$): $P_{ij} = 1$ if $C'_j \subset C'_i \land \neg \exists k [C'_j \subset C'_k \subset C'_i]$ , $0$ otherwise
	\ENSURE output featurization $\mathcal F = \{ f_j \}_{j=1}^M$ such that $(\mathcal F, \Sigma, \mathcal V)$ covers $\mathcal C$
	\STATE
	\STATE classQueue $\leftarrow \{c_k \in C' | \sum_{j=1}^{|C'|}P_{jk} = 1 \}$
	\STATE $i \leftarrow 1$
	\STATE
	\WHILE{classQueue $\neq \varnothing$}
	\STATE $c_k \leftarrow$ \textsc{Pop}(classQueue)
	\STATE $f_i(x) = \begin{cases}
		+ & \mbox{if } x \in c_k \\
		0 & \mbox{otherwise}
		\end{cases} $
	\STATE $\mathcal F \leftarrow \mathcal F \cup f_i$
	\STATE $i \leftarrow i + 1$
	\ENDWHILE
\end{algorithmic}

\vspace{\baselineskip} The algorithm is considered sound if it returns a covering feature set for every valid input. 

\textit{Proof}:




\section{Contrastive underspecification}
achieved by assigning a new feature [+f] to every segment in $X$, and if $Y \setminus X$ (the complement of $X$ with respect to $Y$) is in the input, then [-f] is assigned to every segment in $Y \setminus X$


\vspace{\baselineskip} \noindent \begin{algorithmic}
	\REQUIRE $\mathcal V = \{ +, -, 0 \}$
	\REQUIRE Precompute $C' <- \textsc{IntersectionalClosure}(C)$
	\REQUIRE $\mathcal C'$ is sorted in decreasing order of size ($\forall i, j \, [i < j \rightarrow |C'_i| \geq |C'_j|$)
	\REQUIRE parent matrix $P$ ($|C'| \times |C'|$): $P_{ij} = 1$ if $C'_j \subset C'_i \land \neg \exists k [C'_j \subset C'_k \subset C'_i]$ , $0$ otherwise
	\ENSURE output featurization $\mathcal F = \{ f_j \}_{j=1}^M$ such that $(\mathcal F, \Sigma, \mathcal V)$ covers $\mathcal C$
	\STATE classQueue $\leftarrow \{c_k \in C' | \sum_{j=1}^{|C'|}P_{jk} = 1 \}$
	\STATE $i \leftarrow 1$
	\STATE
	\WHILE{classQueue $\neq \varnothing$}
	\STATE $c_k \leftarrow$ \textsc{Pop}(classQueue)
	\STATE parent $ = \{c_i \in C | P_{ik} = 1\}$
	\STATE $c_k' \leftarrow \mbox{parent } \setminus c_k$
	\IF{$c_k' \in C$}
	\STATE $f_i(x) = \begin{cases}
	+ & \mbox{if } x \in c_k \\
	- & \mbox{if } x \in c_k' \\
	0 & \mbox{otherwise}
	\end{cases} $
	\STATE classQueue $\leftarrow \{x \in \mbox{classQueue} | x \not= c_k' \}$
	\ELSE
	\STATE $f_i(x) = \begin{cases}
	+ & \mbox{if } x \in c_k \\
	0 & \mbox{otherwise}
	\end{cases} $
	\ENDIF
	\STATE $\mathcal F \leftarrow \mathcal F \cup f_i$
	
	\STATE $i \leftarrow i + 1$
	\ENDWHILE
\end{algorithmic}

\section{Contrastive specification}
achieved by assigning a new feature [+f] to every segment in $X$, and [-f] to every segment in $Y \setminus X$ (even if $Y \setminus X$ was not in the input)

\vspace{\baselineskip} \noindent \begin{algorithmic}
	\REQUIRE $\mathcal V = \{ +, -, 0 \}$
	\REQUIRE Precompute $C' <- \textsc{IntersectionalClosure}(C)$
	\REQUIRE $\mathcal C'$ is sorted in decreasing order of size ($\forall i, j \, [i < j \rightarrow |C'_i| \geq |C'_j|$)
	\REQUIRE parent matrix $P$ ($|C'| \times |C'|$): $P_{ij} = 1$ if $C'_j \subset C'_i \land \neg \exists k [C'_j \subset C'_k \subset C'_i]$ , $0$ otherwise
	\ENSURE output featurization $\mathcal F = \{ f_j \}_{j=1}^M$ such that $(\mathcal F, \Sigma, \mathcal V)$ covers $\mathcal C$
	\STATE
	\STATE classQueue $\leftarrow \{c_k \in C' | \sum_{j=1}^{|C'|}P_{jk} = 1 \}$
	\STATE $i \leftarrow 1$
	\STATE
	\WHILE{classQueue $\neq \varnothing$}
	\STATE $c_k \leftarrow$ \textsc{Pop}(classQueue)
	\STATE parent $ = \{c_i \in C | P_{ik} = 1\}$
	\STATE $c_k' \leftarrow \mbox{parent } \setminus c_k$
	\STATE $f_i(x) = \begin{cases}
	+ & \mbox{if } x \in c_k \\
	- & \mbox{if } x \in c_k' \\
	0 & \mbox{otherwise}
	\end{cases} $
	\STATE $C' \leftarrow (C' \cup \{c'_k\})$
	\STATE $\textsc{Recalculate}$ $ P $ from $C'$
	\STATE classQueue $\leftarrow \{c_l \in \mbox{classQueue} | c_l \not= c_k' \ \land \sum_{j=1}^{|C'|}P_{jl} = 1 \}$
	\STATE \textsc{Sort}(classQueue)
	\STATE $\mathcal F \leftarrow \mathcal F \cup f_i$
	
	\STATE $i \leftarrow i + 1$
	\ENDWHILE
\end{algorithmic}

\section{Full specification}
achieved by assigning a new feature [+f] to every segment in $X$, and [-f] to every segment in $\Sigma \setminus X$

\vspace{\baselineskip} \noindent \begin{algorithmic}
	\REQUIRE $\mathcal V = \{ +, - \}$
	\REQUIRE Precompute $C' <- \textsc{IntersectionalClosure}(C)$
	\REQUIRE $\mathcal C'$ is sorted in decreasing order of size ($\forall i, j \, [i < j \rightarrow |C'_i| \geq |C'_j|$)
	\REQUIRE parent matrix $P$ ($|C'| \times |C'|$): $P_{ij} = 1$ if $C'_j \subset C'_i \land \neg \exists k [C'_j \subset C'_k \subset C'_i]$ , $0$ otherwise
	\ENSURE output featurization $\mathcal F = \{ f_j \}_{j=1}^M$ such that $(\mathcal F, \Sigma, \mathcal V)$ covers $\mathcal C$
	\STATE
	\STATE classQueue $\leftarrow \{c_k \in C' | \sum_{j=1}^{|C'|}P_{jk} = 1 \}$
	\STATE $i \leftarrow 1$
	\STATE
	\WHILE{classQueue $\neq \varnothing$}
	\STATE $c_k \leftarrow$ \textsc{Pop}(classQueue)
	\STATE $c_k' \leftarrow \Sigma \setminus c_k$
	\STATE $f_i(x) = \begin{cases}
	+ & \mbox{if } x \in c_k \\
	- & \mbox{if } x \in c_k' \\
	\end{cases} $
	\STATE $C' \leftarrow (C' \cup \{c'_k\})$
	\STATE $\textsc{Recalculate}$ $ P $ from $C'$
	\STATE classQueue $\leftarrow \{c_l \in \mbox{classQueue} | c_l \not= c_k' \ \land \sum_{j=1}^{|C'|}P_{jl} = 1 \}$
	\STATE $\mathcal F \leftarrow \mathcal F \cup f_i$
	
	\STATE $i \leftarrow i + 1$
	\ENDWHILE
\end{algorithmic}

\appendix

\section{Formal proof of the algorithm}

\subsection{Privative underspecification}

\subsection{Contrastive underspecification}

\subsection{Contrastive specification}

\subsection{Full specification}

\end{document}  